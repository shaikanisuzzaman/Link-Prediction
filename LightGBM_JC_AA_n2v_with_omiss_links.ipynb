{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import csv\n",
    "#import skopt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16087\n"
     ]
    }
   ],
   "source": [
    "nodes = dict()\n",
    "\n",
    "with open(\"train-mod.txt\") as file :\n",
    "    end = file.seek(0, 2)\n",
    "    file.seek(0)\n",
    "    while file.tell() != end:\n",
    "        line = file.readline().split()\n",
    "        edges = list(itertools.combinations(line,2))\n",
    "        for i in edges:\n",
    "            if nodes.get(i) == None:\n",
    "                node1 = i[0]\n",
    "                node2 = i[1]\n",
    "                if nodes.get((node2,node1)) == None:\n",
    "                    nodes[i] = 1\n",
    "                else:\n",
    "                    nodes[(node2,node1)] += 1\n",
    "            else:\n",
    "                nodes[i] +=1\n",
    "\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"weighted_graph.csv\", \"w\", newline=\"\") as a_file:\n",
    "\n",
    "    writer = csv.writer(a_file)\n",
    "    for key, value in nodes.items():\n",
    "        writer.writerow([key[0], key[1], value])\n",
    "\n",
    "    a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_weighted_edgelist('weighted_graph.csv', delimiter=',', nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 3816\n",
      "Number of edges: 16087\n",
      "Average degree:   8.4313\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))\n",
    "#print(g.get_edge_data(1655,3650))\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "#adj_G = nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj_G.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving all graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_edges = list(nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"edges_graph_all.csv\",\"w\",newline=\"\") as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow([\"Source\",\"Target\", \"Label\"])\n",
    "    for edge in graph_edges:\n",
    "        writer.writerow([edge[0], edge[1], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos_edges = 1600\n",
    "num_neg_edges = 16087\n",
    "#edges_pos_all = list(nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_node_count = len(g.nodes)\n",
    "\n",
    "df_graph_all = pd.read_csv(\"edges_graph_all.csv\")\n",
    "df_pos_temp = pd.read_csv(\"edges_graph_all.csv\")\n",
    "\n",
    "removable_edges_indices = []\n",
    "\n",
    "ncc = nx.number_connected_components(g)\n",
    "number_of_nodes = len(g.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding positive edges that retain graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16087/16087 [18:35<00:00, 14.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# for each node pair we will be removing a node pair and creating a new graph,\n",
    "# and check if the number of connected components and the number of nodes\n",
    "# are the same as the original graph\n",
    "for i in tqdm(df_pos_temp.index.values):\n",
    "  \n",
    "      # remove a node pair and build a new graph\n",
    "   G1 = nx.from_pandas_edgelist(df_pos_temp.drop(index= i), \"Source\", \"Target\",\n",
    "                                create_using=nx.Graph())\n",
    "  \n",
    "      # If the number of connected components remain same as the original\n",
    "      # graph we won't remove the edge\n",
    "   if (nx.number_connected_components(G1) == ncc) and (len(G1.nodes) == number_of_nodes):\n",
    "       removable_edges_indices.append(i)\n",
    " \n",
    "       # drop the edge, so that for the next iteration the next G1\n",
    "       # is created without this edge\n",
    "       df_pos_temp = df_pos_temp.drop(index = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_pos_edges = df_graph_all.loc[removable_edges_indices]\n",
    "rem_pos_edges.to_csv(\"edges_all_rem_pos.csv\", index=False)\n",
    "\n",
    "pos_edges_selected = random.sample(removable_edges_indices, num_pos_edges)\n",
    "\n",
    "df_pos_valid = df_graph_all.loc[pos_edges_selected]\n",
    "\n",
    "df_pos_valid.to_csv(\"edges_pos_valid2k.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating all negative edges (random sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "num_neg_edges = 16087\n",
    "edges_neg = []\n",
    "while i < num_neg_edges:\n",
    "    edge = random.sample(g.nodes(), 2)\n",
    "    #print(str(edge[0]))\n",
    "    #print(str(edge[1]))\n",
    "    try:\n",
    "        edge_exists = g.has_edge(edge[0],edge[1])\n",
    "        #print(str(edge_exists))\n",
    "        if edge_exists == False:\n",
    "            #print(str(i))\n",
    "            edges_neg.append([edge[0],edge[1]])\n",
    "            i = i+1\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16087"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"edges_neg_all.csv\",\"w\",newline=\"\") as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow([\"Source\",\"Target\", \"Label\"])\n",
    "    for edge in edges_neg:\n",
    "        writer.writerow([edge[0], edge[1], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_all = pd.read_csv(\"edges_neg_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_indices = list(np.arange(16087))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edges_selected = random.sample(neg_indices, num_pos_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_edges_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_valid = df_neg_all.loc[neg_edges_selected]\n",
    "\n",
    "df_neg_valid.to_csv(\"edges_neg_valid2k.csv\", index=False)\n",
    "\n",
    "df_neg_train = df_neg_all.drop(index=df_neg_valid.index.values)\n",
    "\n",
    "df_neg_train.to_csv(\"edges_neg_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_neg_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sub-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_train = df_graph_all.drop(index=df_pos_valid.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_train.to_csv(\"edges_pos_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 3816\n",
      "Number of edges: 14487\n",
      "Average degree:   7.5928\n"
     ]
    }
   ],
   "source": [
    "G_new = nx.from_pandas_edgelist(df_pos_train, \"Source\", \"Target\",\n",
    "                               create_using=nx.Graph())\n",
    "\n",
    "print(nx.info(G_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = pd.read_csv('edges_pos_train.csv')\n",
    "train_neg = pd.read_csv('edges_neg_train.csv')\n",
    "valid_pos = pd.read_csv('edges_pos_valid2k.csv')\n",
    "valid_neg = pd.read_csv('edges_neg_valid2k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_pos.append(train_neg)\n",
    "#data.reset_index(drop=True)\n",
    "data = data.append(valid_pos)\n",
    "data = data.append(valid_neg)\n",
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 3816/3816 [00:04<00:00, 844.55it/s] \n",
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [04:48<00:00,  5.77s/it]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "# Generate walks\n",
    "node2vec = Node2Vec(G_new, dimensions=30, walk_length=16, num_walks=50)\n",
    "\n",
    "# train node2vec model\n",
    "n2w_model = node2vec.fit(window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-60ade5b32268>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  X_n2v = [(n2w_model[str(i)]+n2w_model[str(j)]) for i,j in zip(data['Source'], data['Target'])]\n"
     ]
    }
   ],
   "source": [
    "X_n2v = [(n2w_model[str(i)]+n2w_model[str(j)]) for i,j in zip(data['Source'], data['Target'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node similarity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(sample_list, test = False):\n",
    "    features = []\n",
    "    i = 0\n",
    "    for sample in sample_list:\n",
    "        #print(sample)\n",
    "        source = sample[0]\n",
    "        target = sample[1]\n",
    "        if test == False:\n",
    "            label = sample[2]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        feature = []\n",
    "        try:\n",
    "            i = i+1\n",
    "            #print(i)\n",
    "            \n",
    "            #p = nx.common_neighbors(g, source, target)\n",
    "            #feature.append(len(p))\n",
    "            \n",
    "            #p = nx.simrank_similarity(g, source, target)\n",
    "            #feature.append(p)\n",
    "            \n",
    "            #preds = nx.resource_allocation_index(g, [(source, target)])\n",
    "            #for u, v, p in preds:\n",
    "            #    feature.append(p)\n",
    "\n",
    "            preds = nx.jaccard_coefficient(G_new, [(source, target)])\n",
    "            for u, v, p in preds:\n",
    "                feature.append(p)\n",
    "\n",
    "            preds = nx.adamic_adar_index(G_new, [(source, target)])\n",
    "            for u, v, p in preds:\n",
    "                feature.append(p)\n",
    "\n",
    "            #preds = nx.preferential_attachment(g, [(source, target)])\n",
    "            #for u, v, p in preds:\n",
    "            #    feature.append(p)\n",
    "            \n",
    "            feature.append(label)  # append label\n",
    "            \n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            pass\n",
    "        features.append(feature)\n",
    "    print(\"features: \"+str(len(features)))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 32174\n"
     ]
    }
   ],
   "source": [
    "graph_features = generate_features(data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32174"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_train_to_csv(features):\n",
    "    with open(\"data_graphmetrics.csv\",\"w\",newline=\"\") as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "        writer.writerow([\"JC\",\"AA\",\"Label\"])\n",
    "        writer.writerows(features)\n",
    "        \n",
    "write_train_to_csv(graph_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metrics = pd.read_csv('data_graphmetrics.csv')\n",
    "FEATURE_SIZE=2\n",
    "\n",
    "X_feat = data_metrics.iloc[:,:FEATURE_SIZE].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_feat_scaled = sc.fit_transform(X_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n2v_arr = np.array(X_n2v)\n",
    "all_feats = np.concatenate((X_feat_scaled,X_n2v_arr),axis=1)\n",
    "y = data['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32174"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_feats, y, \n",
    "                                                test_size = 0.1, \n",
    "                                                shuffle = False, stratify = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28956, 32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def objective(trial):\n",
    "    #train_x, test_x, train_y, test_y = train_test_split(all_feats, data['label'], \n",
    "    #                                            test_size = 0.2, \n",
    "    #                                            random_state = 35)\n",
    "    dtrain = lgb.Dataset(x_train, label=y_train)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': 'false',\n",
    "        'boosting': trial.suggest_categorical('boosting', ['gbdt', 'dart']),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "        'max_bin': trial.suggest_int('max_bin', 25, 255),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.5)\n",
    "    }\n",
    " \n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(x_test)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(y_test, pred_labels)\n",
    "    return accuracy\n",
    " \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    " \n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(x_train, y_train)\n",
    "test_data = lgbm.Dataset(x_test, y_test)\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'false',\n",
    "    'boosting': 'dart', 'lambda_l1': 9.195584693502481e-05, 'lambda_l2': 2.9179094500377866e-05, 'num_leaves': 81, 'feature_fraction': 0.4429293323344315, 'bagging_fraction': 0.5910964246323879, 'bagging_freq': 7, 'min_child_samples': 11, 'subsample': 0.19049703012014824, 'max_depth': 15, 'max_bin': 226, 'learning_rate': 0.06381081570044855\n",
    "    }\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1373ef0b940>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Saving model...')\n",
    "# save model to file\n",
    "model.save_model('n2v_metrics_LGBM_optuna_V1_300.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCols=['Id', 'source_node', 'destination_node'] \n",
    "df_test_public = pd.read_csv('test-public.csv')\n",
    "ids = df_test_public['Id'].values\n",
    "df_test_public.columns = testCols\n",
    "df_test_public = df_test_public.drop('Id', axis = 1)\n",
    "df_test_public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-114-2271668228b8>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  x_testing_n2v = [(n2w_model[str(i)]+n2w_model[str(j)]) for i,j in zip(df_test_public['source_node'], df_test_public['destination_node'])]\n"
     ]
    }
   ],
   "source": [
    "x_testing_n2v = [(n2w_model[str(i)]+n2w_model[str(j)]) for i,j in zip(df_test_public['source_node'], df_test_public['destination_node'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 2000\n"
     ]
    }
   ],
   "source": [
    "test_features = generate_features(df_test_public.to_numpy(), test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_to_csv(features):\n",
    "    with open(\"test.csv\",\"w\",newline=\"\") as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "        writer.writerow([\"JC\",\"AA\",\"Label\"])\n",
    "        writer.writerows(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test_to_csv(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('test.csv')\n",
    "FEATURE_SIZE=2\n",
    "\n",
    "X_test_feat = dataset_test.iloc[:,:FEATURE_SIZE].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_feat_scaled = sc.fit_transform(X_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_n2v_arr = np.array(x_testing_n2v)\n",
    "all_test_feats = np.concatenate((X_test_feat_scaled,X_test_n2v_arr),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(all_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': ids, 'Predicted': y_pred})\n",
    "output.to_csv(\"n2v_feats_LGBM_opt_300_Nan1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
